\documentclass{article}
\usepackage{vmlmacros}

\title{Overview of our Languages}
\author{Roger Burtonpatel}
\date{November 24, 2023}
\begin{document}
\maketitle

The first of our languages is $P^{+}$. This is the language of patterns. We know
we can compile patterns into decision trees. Our next language is $V^{-}$, the
language of equations. This uses the decision making construct \it{if-fi} to
perform different operations based on the form of a value. 

Both of these languages theoretically can be compiled to $D$, the language
of decision trees. 


\dots

Because of the $\alpha$, the right-hand side becomes immaterial: we don't care
about what we're returning; we care about the decision-making construct that
gets us there. Whether it's a single value (ML-style) a sequence of values
(Verse-style), or even something else, the $\alpha$ represents \it{any} ultimate
result of "making a decision," and it's the ways in which we make decisions that
we truly care about examining. By making the return result both polymorphic and
abstract, we eschew the need to worry about its type and compatibility with
other results of otherwise-equivalent trees. 

\end{document}